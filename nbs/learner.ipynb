{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b47a208a-d0b7-4611-9fbe-2cd69a42678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export a nas [las m],]m  \n",
    "import torch\n",
    "from torchmetrics import MeanMetric\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import to_cpu,CancelFitException,CancelBatchException,CancelEpochException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "773713eb-9236-4366-9107-f28c2769c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class with_clb():\n",
    "    def __init__(self,name):\n",
    "        self.name=name\n",
    "    def __call__(self,f_):\n",
    "        def f(o,*args,**kwargs):\n",
    "\n",
    "            if True in args:o.train_phase = True\n",
    "            if False in args:o.train_phase = False\n",
    "            if 'train' in kwargs.keys():o.train_phase = True if kwargs['train'] else False\n",
    "            \n",
    "            try:\n",
    "                o.callback(f'{self.name}_start')\n",
    "                f_(o,*args,**kwargs)\n",
    "                o.callback(f'{self.name}_end')\n",
    "            except globals()[f'Cancel{self.name.title()}Exception']: pass\n",
    "            finally:o.callback(f'{self.name}_cleanup')\n",
    "        \n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0deb40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class Learner():\n",
    "    \n",
    "    def __init__(self,model,loss_func,optim,cbs=[]):\n",
    "        self.model,self.loss_func,self.optim,self.cbs = model,loss_func,optim,cbs\n",
    "        for cb in self.cbs:cb.learner = self\n",
    "        \n",
    "    def predict(self):\n",
    "        self.xb,self.yb = self.batch\n",
    "        self.preds = self.model(self.xb)\n",
    "    def get_loss(self):self.loss = self.loss_func(self.preds,self.yb)\n",
    "    def backward(self):self.loss.backward()\n",
    "    def step(self):self.optim.step()\n",
    "    def zero_grad(self):self.optim.zero_grad()\n",
    "        \n",
    "        \n",
    "    @with_clb('batch')\n",
    "    def one_batch(self,train=True):\n",
    "        self.model.training = train\n",
    "        self.predict()\n",
    "        self.callback('after_predict')\n",
    "        self.get_loss()\n",
    "        self.callback('after_loss')\n",
    "        if self.model.training:\n",
    "            self.backward()\n",
    "            self.callback('after_backward')\n",
    "            self.step()\n",
    "            self.callback('after_step')\n",
    "            self.zero_grad()\n",
    "            \n",
    "    @with_clb('epoch')\n",
    "    def one_epoch(self,dl,train=True):\n",
    "        \n",
    "        for self.batch in dl:\n",
    "            self.one_batch(train) \n",
    "     \n",
    "    @with_clb('fit')\n",
    "    def _fit(self):\n",
    "        for self.epoch in range(1,self.n_epochs+1):\n",
    "            self.one_epoch(self.train_dl,True)\n",
    "            if self.valid_dl is not None:self.one_epoch(self.valid_dl,False)\n",
    "    \n",
    "    \n",
    "    def fit(self,train_dl,n_epochs,valid_dl=None,tmp_cbs=[]):       \n",
    "        self.n_epochs,self.train_dl,self.valid_dl = n_epochs,train_dl,valid_dl\n",
    "        self.add_cbs(tmp_cbs)\n",
    "        self._fit()\n",
    "        self.remove_cbs(tmp_cbs)\n",
    "        \n",
    "    def callback(self,name):\n",
    "        for cb in self.cbs:\n",
    "            method = getattr(cb,name,None)\n",
    "            if method is not None:method()\n",
    "            \n",
    "    def add_cbs(self,cbs):\n",
    "        for cb in cbs:\n",
    "            self.cbs.append(cb)\n",
    "            cb.learner=self\n",
    "        \n",
    "    def remove_cbs(self,cbs):\n",
    "        for cb in cbs:self.cbs.remove(cb)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c202dfb-48b9-45d3-827b-2c57cdd9c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class DeviceCB():\n",
    "    def __init__(self,device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')):\n",
    "        print(f'is cuda available:{torch.cuda.is_available()}')\n",
    "        print(f'device count:{torch.cuda.device_count()}')\n",
    "        self.device = device\n",
    "    def fit_start(self):self.learner.model.to(self.device)\n",
    "    def batch_start(self):self.learner.batch = self.to_device(self.learner.batch)\n",
    "    def to_device(self,x):\n",
    "        if isinstance(x, dict): return {k:self.to_device(v) for k,v in x.items()}\n",
    "        if isinstance(x, list): return [self.to_device(o) for o in x]\n",
    "        if isinstance(x, tuple): return tuple(self.to_device(list(x)))\n",
    "        return x.to(self.device)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49041dbf-683e-4246-997c-6af170c3287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class MetricsCB():\n",
    "    def __init__(self,*ms,**metrics):\n",
    "        for m in ms:metrics[type(m).__name__]=m\n",
    "        self.metrics = metrics\n",
    "        self.loss = MeanMetric()\n",
    "    def fit_start(self):self.learner.metrics = self\n",
    "    def epoch_start(self):\n",
    "        for m in self.metrics.values():m.reset()\n",
    "        self.loss.reset()\n",
    "    def batch_end(self):\n",
    "        preds,yb = to_cpu(self.learner.preds),to_cpu(self.learner.yb)\n",
    "        for m in self.metrics.values():m.update(preds,yb)\n",
    "        self.loss.update(to_cpu(self.learner.loss),len(yb))\n",
    "    def _log(self,log):\n",
    "        print(log)\n",
    "    def epoch_end(self):\n",
    "        log={'epoch':self.learner.epoch,'istrain':self.learner.train_phase}\n",
    "        log['loss']=self.loss.compute()\n",
    "        for k,v in self.metrics.items():log[k]= v.compute()\n",
    "        self._log(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69b96cec-d068-4a8e-be4d-e63c5a437f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class PlotCB():\n",
    "\n",
    "    def __init__(self,skip=25,trackmetrics=False,xlim=None,ylim=None,**kwargs):\n",
    "        self.skip = skip\n",
    "        self.trackmetrics=trackmetrics\n",
    "        self.fig,self.ax = plt.subplots(**kwargs)\n",
    "        if xlim is not None:self.ax.set_xlim(*xlim)\n",
    "        if ylim is not None:self.ax.set_ylim(*ylim)\n",
    "        plt.close()\n",
    "        self.graph={}\n",
    "        self._c = ['k','y','m','c','g','r','b']\n",
    "        \n",
    "    def display(self):self.fig_out = display(self.fig,display_id=True)\n",
    "    \n",
    "    def add_point(self,x,y,label='default'):\n",
    "        if label not in self.graph.keys():self.graph[label]={'x':[x],'y':[y],'c':self._c.pop()}\n",
    "        else:\n",
    "            self.graph[label]['x'].append(x)\n",
    "            self.graph[label]['y'].append(y)\n",
    "\n",
    "    def plot(self,*args,**kwargs):\n",
    "        self.ax.clear()\n",
    "        for label,d in self.graph.items():\n",
    "            ispoint = (len(d['x'])==1)\n",
    "            self.ax.plot(d['x'],d['y'],f'{d[\"c\"]}{\"o--\" if ispoint else \"\"}',label=label,*args,**kwargs)\n",
    "        self.ax.legend()\n",
    "        self.fig_out.update(self.fig)\n",
    "        \n",
    "    def fit_start(self):\n",
    "        if not hasattr(self.learner,'metrics'):raise Exception(\"PlotCB shoudn't be before MetricsCB\")\n",
    "        self.metrics = self.learner.metrics\n",
    "        if not hasattr(self,'batch_count'):self.batch_count = 0\n",
    "        self.display()\n",
    "        \n",
    "    def batch_end(self):\n",
    "        if self.learner.train_phase:\n",
    "            self.batch_count = self.batch_count+1\n",
    "            self.add_point(self.batch_count,to_cpu(self.learner.loss),label=\"train_loss\")\n",
    "            if self.batch_count%self.skip==1:\n",
    "                self.plot()\n",
    "\n",
    "    def epoch_end(self):\n",
    "        if not self.learner.train_phase:\n",
    "            self.add_point(self.batch_count,self.metrics.loss.compute(),label=\"valid_loss\") \n",
    "            if self.trackmetrics:\n",
    "                for name,m in self.metrics.metrics.items():\n",
    "                    self.add_point(self.batch_count,m.compute(),label=f'valid_{name}')\n",
    "            self.plot()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d386a382-0afe-4f2c-9fac-eaeb5a9770b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_utils import exportnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0e18ae-0fab-4a46-906d-ea5028cbac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportnb('learner.ipynb','learner.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8fed3-595e-431e-a99e-89f8942a68f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
