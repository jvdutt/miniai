{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf5aef4-f8ff-4d34-a020-13b7924cefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import Hook,to_cpu\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df6ea2-5fed-4c9c-b94a-93087620b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class ActivationStats():\n",
    "    def __init__(self,ms):\n",
    "        self.hooks = [Hook(m,self.append_stats) for m in ms]\n",
    "    def append_stats(self,h,mod,inp,out):\n",
    "        if not hasattr(h,'stats'):h.stats=[[],[],[]]\n",
    "        out = to_cpu(out)\n",
    "        h.stats[0].append(out.mean())\n",
    "        h.stats[1].append(out.std())\n",
    "        h.stats[2].append(out.abs().histc(40,0,10))\n",
    "    def get_hist_image(self,h):\n",
    "        return torch.stack(h.stats[2]).T.float().log1p()\n",
    "    def get_dead_percentage(self,h):\n",
    "        hist = torch.stack(h.stats[2])\n",
    "        return hist[:,0]/hist.sum(1)\n",
    "    def plot_histograms(self,figsize=None):\n",
    "        for h in self.hooks:\n",
    "            fig,ax = plt.subplots(figsize=figsize)\n",
    "            ax.imshow(self.get_hist_image(h))\n",
    "            ax.invert_yaxis()\n",
    "            ax.set_yticks([_*2 for _ in range(20)],labels=[_/2 for _ in range(20)])\n",
    "            plt.show()\n",
    "    def plot_dead_chart(self,figsize=None):\n",
    "        for h in self.hooks:\n",
    "            fig,ax = plt.subplots(figsize=figsize)\n",
    "            ax.plot(self.get_dead_percentage(h))\n",
    "            ax.set_ylim(0,1)\n",
    "            plt.show()\n",
    "            \n",
    "    def plot_stats(self,figsize=None):\n",
    "        fig,axs = plt.subplots(1,2,figsize=figsize)\n",
    "        for e,h in enumerate(self.hooks):\n",
    "            for i in 0,1:\n",
    "                axs[i].plot(h.stats[i],label=f'{e}')\n",
    "        axs[0].set_title(\"Means\")\n",
    "        axs[1].set_title(\"Stds\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96cb30c-9ed5-4045-86a7-341ff519ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class Normalizer(nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self.n = nn.BatchNorm2d(*args,**kwargs)\n",
    "        for p in self.n.parameters():p.requires_grad_(False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7078b5ac-cd01-4430-81a4-962b5ca9b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class LsuvInit():\n",
    "    def __init__(self,learner,modules,dl,take_first_batch=False,max_iter=10,tol=1e-5,orthogonal=True,device=None):\n",
    "        if device is None:device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        learner.model.to(device)\n",
    "        data = next(iter(dl)) if take_first_batch else iter(self.circle(dl))\n",
    "        for m in modules:\n",
    "            h = Hook(m,self.get_stats)\n",
    "            self.orthogonal_init(m,orthogonal)\n",
    "            for i in range(max_iter):\n",
    "                learner.batch = data if take_first_batch else next(data)\n",
    "                learner.batch = self.to_device(learner.batch,device)\n",
    "                with torch.no_grad():\n",
    "                    learner.predict()\n",
    "                    print(m,h.mean,h.std)\n",
    "                    if abs(h.std-1)<tol:\n",
    "                        if hasattr(m,\"bias\") and (m.bias is not None):\n",
    "                            if abs(h.mean)<tol:break\n",
    "                        else:break\n",
    "                    if hasattr(m,\"weight\") and (m.weight is not None):m.weight/=h.std\n",
    "                    if hasattr(m,\"bias\") and (m.bias is not None):m.bias-=h.mean\n",
    "            h.remove()\n",
    "            \n",
    "    def orthogonal_init(self,m,orth):\n",
    "        if orth and hasattr(m,\"weight\") and (m.weight is not None):\n",
    "            with torch.no_grad():m.weight.data = torch.from_numpy(self.svd_orthonormal(m.weight.numpy()))\n",
    "            \n",
    "    def svd_orthonormal(self,w):\n",
    "        shape = w.shape\n",
    "        if len(shape) < 2:\n",
    "            raise RuntimeError(\"Only shapes of length 2 or more are supported.\")\n",
    "        flat_shape = (shape[0], np.prod(shape[1:]))\n",
    "        a = np.random.normal(0.0, 1.0, flat_shape)#w;\n",
    "        u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "        q = u if u.shape == flat_shape else v\n",
    "        q = q.reshape(shape)\n",
    "        return q.astype(np.float32)\n",
    "                \n",
    "    def get_stats(self,h,mod,inp,out):\n",
    "        out = to_cpu(out)\n",
    "        h.mean = out.mean()\n",
    "        h.std = out.std()\n",
    "        \n",
    "    def circle(self,dl):\n",
    "        while True:\n",
    "            for batch in dl:yield batch \n",
    "            \n",
    "    def to_device(self,x,device):\n",
    "        if isinstance(x, dict): return {k:self.to_device(v,device) for k,v in x.items()}\n",
    "        if isinstance(x, list): return [self.to_device(o,device) for o in x]\n",
    "        if isinstance(x, tuple): return tuple(self.to_device(list(x),device))\n",
    "        return x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32234be2-2b70-45f9-9fdf-de991046c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "def get_modules(model,module_names):\n",
    "    return list(filter(partial(lambda x,y:isinstance(y,x),module_names),model.modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafe69de-a85c-434e-a45b-7fa22faa242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_utils import exportnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0210758-379b-468d-9dba-1b4a9e8ee72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportnb(\"init.ipynb\",\"init.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28733bcd-c1f2-4ed3-9cde-93bf8b21bd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
