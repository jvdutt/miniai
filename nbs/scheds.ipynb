{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee63bc-bb91-4198-bad6-d807df40a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import to_cpu,CancelEpochException,CancelFitException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c643e233-e7ad-4063-b5cb-3cd7782f8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class SchedulerFunction:\n",
    "    def __init__(self,sp,ep,L):\n",
    "        self.sp,self.ep,self.L = sp,ep,L\n",
    "    def __call__(self,i):\n",
    "        pass\n",
    "    def plot(self,x):\n",
    "        plt.plot(x,[self(i) for i in x],\"--ok\")\n",
    "        \n",
    "class cos_sched(SchedulerFunction):\n",
    "    def __call__(self,i):\n",
    "        sp,ep,L = self.sp,self.ep,self.L\n",
    "        m,c,x = sp-ep,(ep+sp)/2,math.cos(i*math.pi/L)/2\n",
    "        return m*x + c\n",
    "    \n",
    "class exp_sched(SchedulerFunction):\n",
    "    def __call__(self,i):\n",
    "        sp,ep,L = self.sp,self.ep,self.L\n",
    "        return sp*(ep/sp)**(i/L)\n",
    "    \n",
    "class lin_sched(SchedulerFunction):\n",
    "    def __call__(self,i):\n",
    "        sp,ep,L = self.sp,self.ep,self.L\n",
    "        return sp + i*((ep-sp)/L) \n",
    "    \n",
    "class concat_scheds(SchedulerFunction):\n",
    "    \n",
    "    def __init__(self,scheds,L=None,perc=None):\n",
    "        if L is not None:\n",
    "            if perc is None:perc=[1/len(scheds)]*len(scheds)\n",
    "            assert len(perc)==len(scheds)\n",
    "            tot = sum(perc) \n",
    "            Ls = [int(L*p/tot) for p in perc]\n",
    "            for sched,l in zip(scheds,Ls):sched.L=l\n",
    "        x = [0]\n",
    "        for sched in scheds:x.append(x[-1]+sched.L)\n",
    "        self.x = x[:-1]\n",
    "        self.scheds = scheds\n",
    "        \n",
    "    def __call__(self,i):\n",
    "        for e,point in enumerate(self.x[1:]):\n",
    "            if i<=point:return self.scheds[e](i-self.x[e])\n",
    "        return self.scheds[-1](i-self.x[-1])\n",
    "    \n",
    "class stack_scheds(SchedulerFunction):\n",
    "    def __init__(self,scheds):\n",
    "        self.scheds=scheds\n",
    "    def __call__(self,i):\n",
    "        return tuple(sched(i) for sched in self.scheds)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af05de0-bbb3-4693-b314-fdec7c523c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class Schedule:\n",
    "    def __init__(self,optim,**kwargs):\n",
    "        self.optim = optim\n",
    "        self.optim_init_state_dict = self.optim.state_dict()\n",
    "        self.count = 0\n",
    "        n = len(self.optim.param_groups)\n",
    "        \n",
    "        self.recorder=[{} for i in range(n)]\n",
    "        self.schedulers=[{} for i in range(n)]\n",
    "        for k,v in kwargs.items():\n",
    "            if k not in self.optim.param_groups[0]:raise AttributeError(f\"No {k} in optimizers\") \n",
    "            if type(v) is not list:kwargs[k]=[v for i in range(n)]\n",
    "            assert n==len(kwargs[k])\n",
    "            for recorder_pg in self.recorder:recorder_pg[k]=None\n",
    "            for sched,sched_pg in zip(kwargs[k],self.schedulers):sched_pg[k]=sched\n",
    "\n",
    "        \n",
    "    def reset(self,optim=True,count=True,recorder=False):\n",
    "        if optim:self.optim.load_state_dict(self.optim_init_state_dict)\n",
    "        if count:self.count=0\n",
    "        if recorder:\n",
    "            for recorder_pg in self.recorder:\n",
    "                for k in recorder_pg:recorder_pg[k]=None\n",
    "    \n",
    "    def step(self):\n",
    "        for optim_pg,sched_pg,recorder_pg in zip(self.optim.param_groups,self.schedulers,self.recorder):\n",
    "            for k in sched_pg:\n",
    "                value = sched_pg[k](self.count)\n",
    "                optim_pg[k] = value\n",
    "                recorder_pg[k] = value\n",
    "        self.count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0d454-bc7e-47b4-a50d-d5b9f862bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "class BatchScheduleCB:\n",
    "    def __init__(self,schedule):\n",
    "        self.schedule = schedule\n",
    "    \n",
    "    def fit_start(self):\n",
    "        self.schedule.step()\n",
    "        \n",
    "    def batch_end(self):\n",
    "        if self.learner.train_phase:self.schedule.step()\n",
    "        \n",
    "class EpochScheduleCB:\n",
    "    def __init__(self,schedule):\n",
    "        self.schedule = schedule\n",
    "    \n",
    "    def fit_start(self):\n",
    "        self.schedule.step()\n",
    "        \n",
    "    def epoch_end(self):\n",
    "        if self.learner.train_phase:self.schedule.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e034b3-1246-4eb9-ae76-a98a567d54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "\n",
    "class LRfinderCB:\n",
    "    def __init__(self,sps=[1e-5],gammas=[1.1],max_mul=3,mom=0.9):\n",
    "        self.sched_funcs = []\n",
    "        for sp,gamma in zip(sps,gammas):self.sched_funcs.append(exp_sched(sp,sp*gamma,1))\n",
    "        self.max_mul=max_mul\n",
    "        self.buffer,self.mom,self.n=torch.tensor(0.0),mom,0\n",
    "        \n",
    "    def smooth_loss(self,loss):\n",
    "        self.n+=1\n",
    "        self.buffer.lerp_(loss,1-self.mom)\n",
    "        return self.buffer/(1-self.mom**self.n)\n",
    "        \n",
    "        \n",
    "    def fit_start(self):\n",
    "        assert len(self.sched_funcs)==len(self.learner.optim.param_groups)\n",
    "        self.sched = Schedule(self.learner.optim,lr=self.sched_funcs)\n",
    "        self.exp_avg_losses=[]\n",
    "        self.losses=[]\n",
    "        self.min_loss = math.inf\n",
    "        self.lr_records = [[] for i in range(len(self.learner.optim.param_groups))]\n",
    "        self.sched.step()\n",
    "        for e,r in enumerate(self.sched.recorder):self.lr_records[e].append(r[\"lr\"])\n",
    "        \n",
    "     \n",
    "    def batch_end(self):\n",
    "        if not self.learner.train_phase:raise CancelEpochException()\n",
    "        loss = to_cpu(self.learner.loss)\n",
    "        self.losses.append(loss)\n",
    "        loss = self.smooth_loss(loss)\n",
    "        self.exp_avg_losses.append(loss)\n",
    "        if loss<self.min_loss:self.min_loss=loss\n",
    "        if math.isnan(loss) or loss>self.max_mul*self.min_loss:raise CancelFitException()\n",
    "        self.sched.step()\n",
    "        for e,r in enumerate(self.sched.recorder):self.lr_records[e].append(r[\"lr\"])\n",
    "        \n",
    "    def fit_cleanup(self):\n",
    "        for lr_record in self.lr_records:\n",
    "            plt.plot(lr_record[:-1],self.exp_avg_losses[:-1])\n",
    "            plt.xscale(\"log\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe0475a-6bcb-436a-9a8b-049577c76564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/export\n",
    "def one_cycle_schedfuncs(L,beta2=None,max_lr=[1e-1],div_factor=[25],max_mom=[0.95],min_mom=[0.85],pct=[0.3],final_div_factor=None):\n",
    "    if final_div_factor is None:final_div_factor=div_factor\n",
    "    lr_sched_funcs,beta1_sched_funcs = [],[]\n",
    "    for lr,df,hm,lm,p,f_df in zip(max_lr,div_factor,max_mom,min_mom,pct,final_div_factor):\n",
    "        lr_sched_funcs.append(concat_scheds([cos_sched(lr/df,lr,1),cos_sched(lr,lr/f_df,1)],L,[p,1-p]))\n",
    "        beta1_sched_funcs.append(concat_scheds([cos_sched(hm,lm,1),cos_sched(lm,hm,1)],L,[p,1-p]))\n",
    "    if beta2 is not None:\n",
    "        if not isinstance(beta2,float):raise Exception(\"beta2 is not float\")\n",
    "        beta2_sched_func = lin_sched(beta2,beta2,1)\n",
    "        for i in range(len(beta1_sched_funcs)):beta1_sched_funcs[i] = stack_scheds([beta1_sched_funcs[i],beta2_sched_func])\n",
    "    return lr_sched_funcs,beta1_sched_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911a090a-df93-4789-b695-5123702c1487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_utils import exportnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d71cd5-d3cf-4a05-bd78-0c6b4c2fbae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportnb(\"scheds.ipynb\",\"scheds.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44c8f4-a085-4223-93c2-cf1eea17d049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
